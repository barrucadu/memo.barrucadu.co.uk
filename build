#!/usr/bin/env python3

"""build

Usage:
  build [--drafts] [--cache=<dir>] [--out=<dir>] [--root=<url>]
  build (-h | --help)

Options:
  -h --help       Show this screen.
  --drafts        Include draft memos as well.
  --cache=<dir>   Directory to cache generated HTML in [default: _cache]
  --out=<dir>     Directory to generate site in [default: _site]
  --root=<url>    Root of the website [default: https://memo.barrucadu.co.uk/]

"""

import hashlib
import jinja2
import json
import pypandoc
import shutil
import subprocess
import yaml

from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from docopt import docopt
from pathlib import Path

args = docopt(__doc__)
OUT_DIR = args["--out"]
BASE_HREF = args["--root"]
DRAFT_MODE = args["--drafts"]
CACHE_DIR = args["--cache"]

JINJA2_ENV = jinja2.Environment(
    autoescape=jinja2.select_autoescape(["html", "xml"]),
    loader=jinja2.FileSystemLoader("_templates"),
)

TAXON_DIR = "taxon"

DATE_ISO_FORMAT = "%Y-%m-%d"
DATE_PP_FORMAT = "%b %-d, %Y"


# this is a list so they can be ordered
TAXA = [
    {"name": "General", "slug": "general"},
    {"name": "Games", "slug": "games"},
    {"name": "Research", "slug": "research"},
    {"name": "Deja Fu / CoCo", "slug": "research-dejafucoco", "parent": "research"},
    {"name": "Summaries", "slug": "research-summary", "parent": "research"},
    {"name": "Tech Docs", "slug": "techdocs"},
    {"name": "Self", "slug": "self"},
    {"name": "Possessions", "slug": "self-possessions", "parent": "self"},
    {"name": "Systems", "slug": "self-systems", "parent": "self"},
]

TAXA_BY_SLUG = {taxon["slug"]: taxon for taxon in TAXA}

DEFAULT_TAXON = "general"

for taxon in TAXA:
    taxon["long_name"] = taxon["name"]
    taxon["has_children"] = False
    taxon["link"] = f"{TAXON_DIR}/{taxon['slug']}.html"
    taxon["permalink"] = f"{BASE_HREF}{taxon['link']}"
    taxon["feed_link"] = f"{TAXON_DIR}/{taxon['slug']}.xml"
    taxon["feed_permalink"] = f"{BASE_HREF}{taxon['feed_link']}"
    taxon["parent"] = taxon.get("parent", "")
    if taxon["parent"]:
        parent = TAXA_BY_SLUG[taxon["parent"]]
        parent["has_children"] = True
        taxon["long_name"] = f"{parent['long_name']} ({taxon['name']})"
        taxon["parent_name"] = parent["long_name"]
        taxon["parent_link"] = parent["link"]
        taxon["draft"] = taxon.get("draft", parent.get("draft", False))


def title_for(taxon=None):
    """Title for a memo listing or feed."""

    if taxon is not None:
        return f"barrucadu's memos - {taxon['long_name']}"
    else:
        return "barrucadu's memos"


def make_html(filename, link, text):
    """Render a memo's content using pandoc."""

    text_hash = hashlib.sha256()
    text_hash.update(text.encode())
    cache_file = Path(CACHE_DIR, f"sha256-{text_hash.hexdigest()}.json")

    try:
        cached = json.loads(cache_file.read_text())
        return cached["html"]
    except (OSError, json.decoder.JSONDecodeError):
        pass

    fmt = filename.suffix[1:]
    if fmt == "lhs":
        fmt = "markdown+literate_haskell"

    html = pypandoc.convert_text(
        text,
        "html",
        format=fmt,
        filters=[
            "pandoc-filter-transform-code",
        ],
        extra_args=[
            "--no-highlight",
            "--wrap=none",
        ],
    )

    # this can't be done as a pandoc filter sadly, because the footnote
    # links don't exist when the filter runs
    html = html.replace('href="#fn', f'href="{link}#fn')

    try:
        cache_file.write_text(json.dumps({"html": html}))
    except OSError as err:
        print(f"could not cache generated HTML for {link}: {err.strerror}")

    return html


def make_toc(memo):
    """Generate the full table of contents for a memo."""

    soup = BeautifulSoup(memo["body"], features="html.parser")
    if "toc" in memo:

        def link_titles(soup, links):
            for link in links:
                if "anchor" in link and "title" not in link:
                    link["title"] = soup.find(id=link["anchor"]).text
                if "children" in link:
                    link["children"] = link_titles(soup, link["children"])
            return links

        return link_titles(soup, memo["toc"])
    else:
        toc = []
        for tag in soup.find_all("h2"):
            toc.append(
                {
                    "title": tag.text,
                    "anchor": tag["id"],
                }
            )
        return toc


def load_page(fpath):
    lines = fpath.read_text().splitlines()
    metadata_end_idx = lines[1:].index("---") + 1
    text_start_idx = metadata_end_idx + 1

    page = yaml.load("\n".join(lines[1:metadata_end_idx]), Loader=yaml.SafeLoader)
    page["filename"] = fpath.name
    page["slug"] = fpath.stem
    page["link"] = f"{page['slug']}.html"
    page["permalink"] = f"{BASE_HREF}{page['slug']}.html"

    # render the body
    page["text"] = "\n".join(lines[text_start_idx:])
    page["body"] = make_html(fpath, page["link"], page["text"])

    return page


ALL_ERRORS = []
for fpath in Path("errors").iterdir():
    if not fpath.is_file():
        continue

    page = load_page(fpath)
    ALL_ERRORS.append(page)

ALL_MEMOS = []
for fpath in Path("memos").iterdir():
    if not fpath.is_file():
        continue

    memo = load_page(fpath)
    toc = make_toc(memo)
    if toc:
        memo["toc"] = toc

    # timestamps
    if "published" not in memo:
        datestr = subprocess.check_output(
            [
                "git",
                "log",
                "--diff-filter=A",
                "--follow",
                "--date=short",
                "--format=%ad",
                "-1",
                "--",
                fpath,
            ]
        )
        try:
            memo["published"] = datetime.strptime(
                datestr.decode("utf-8").strip(), "%Y-%m-%d"
            )
        except Exception:
            # this will be reached if the file hasn't been committed
            memo["published"] = datetime.now()
    memo["modified"] = memo.get("modified", memo.get("date", memo["published"]))
    if not isinstance(memo["published"], datetime):
        memo["published"] = datetime(
            memo["published"].year, memo["published"].month, memo["published"].day
        )
    if not isinstance(memo["modified"], datetime):
        memo["modified"] = datetime(
            memo["modified"].year, memo["modified"].month, memo["modified"].day
        )
    if memo["published"] > memo["modified"]:
        memo["published"] = memo["modified"]

    memo["published_iso"] = memo["published"].strftime(DATE_ISO_FORMAT)
    memo["published_pp"] = memo["published"].strftime(DATE_PP_FORMAT)
    memo["modified_iso"] = memo["modified"].strftime(DATE_ISO_FORMAT)
    memo["modified_pp"] = memo["modified"].strftime(DATE_PP_FORMAT)

    # get the taxon
    taxon_slug = memo.get("taxon", DEFAULT_TAXON)
    taxon = TAXA_BY_SLUG[taxon_slug]
    memo["taxon"] = taxon
    memo["taxa"] = [taxon]
    while taxon["parent"]:
        taxon = TAXA_BY_SLUG[taxon["parent"]]
        memo["taxa"].append(taxon)

    if memo.get("draft", False) and not DRAFT_MODE:
        continue
    ALL_MEMOS.append(memo)

MEMOS_BY_SLUG = {memo["slug"]: memo for memo in ALL_MEMOS}
for memo in ALL_MEMOS:
    if "superseded_by" in memo:
        memo["superseded_by"] = MEMOS_BY_SLUG[memo["superseded_by"]]

HASHED_LINKS = {}
for fpath in Path("hashed-static").iterdir():
    if not fpath.is_file():
        continue

    file_hash = hashlib.sha256()
    with fpath.open("rb") as f:
        while True:
            data = f.read(65536)
            if not data:
                break
            file_hash.update(data)
    HASHED_LINKS[fpath.name] = (
        f"{fpath.stem}-sha256-{file_hash.hexdigest()}{fpath.suffix}"
    )


def render(link, template, **metadata):
    Path(OUT_DIR, link).write_text(
        JINJA2_ENV.get_template(template).render(
            base_href=BASE_HREF,
            hashed_links=HASHED_LINKS,
            site_name=title_for(),
            is_root=link == "index.html",
            is_memo=template == "memo.html",
            link=link,
            permalink=f"{BASE_HREF}{link}",
            **metadata,
        )
    )


def render_memo_list(memos, taxon=None, taxa=[]):
    """Render a memo listing page."""

    metadata = {
        "title": title_for(taxon=taxon),
        "taxa": taxa,
    }

    link = "index.html"
    if taxon is not None:
        link = f"{TAXON_DIR}/{taxon['slug']}.html"
        metadata["taxon"] = taxon
        memos = [memo for memo in memos if taxon in memo["taxa"]]

    if memos:
        metadata["memos"] = memos
    else:
        raise Exception(f"no memos (taxon={taxon})")

    render(link, "index.html" if link == "index.html" else "list.html", **metadata)


def render_memo_feed(memos, taxon=None, num=10):
    """Render a memo listing feed."""

    link = "atom.xml"
    if taxon is not None:
        link = f"{TAXON_DIR}/{taxon['slug']}.xml"
        memos = [memo for memo in memos if taxon in memo["taxa"]]

    metadata = {
        "title": title_for(taxon=taxon),
        "taxon": taxon,
        "memos": memos[:num],
    }
    if memos:
        metadata["feed_date"] = memos[0]["modified_iso"]

    render(link, "atom.xml", **metadata)


def memo_sort_key(memo, sort_important=True):
    timestamp = memo["modified"]

    # bump up important memos (should I retire this field, perhaps?)
    if sort_important and "important" in memo:
        timestamp += timedelta(days=365 * 1000)

    return timestamp


memos_for_lists = sorted(
    [memo for memo in ALL_MEMOS if "superseded_by" not in memo],
    key=lambda memo: memo_sort_key(memo, True),
    reverse=True,
)

memos_for_feeds = sorted(
    [memo for memo in memos_for_lists],
    key=lambda memo: memo_sort_key(memo, False),
    reverse=True,
)

###############################################################################
# Here be effects

shutil.rmtree(OUT_DIR, ignore_errors=True)
shutil.copytree("static", OUT_DIR)
shutil.copytree("MathJax/es5", Path(OUT_DIR, "mathjax"))
Path(OUT_DIR, TAXON_DIR).mkdir()

for source, target in HASHED_LINKS.items():
    shutil.copy(Path("hashed-static", source), Path(OUT_DIR, target))

render("robots.txt", "robots.txt")
render("sitemap.xml", "sitemap.xml", memos=ALL_MEMOS, taxa=TAXA)

render_memo_list(memos_for_lists, taxa=TAXA)
render_memo_feed(memos_for_feeds)


def build_taxon_pages_recursive(taxon):
    render_memo_list(memos_for_lists, taxon=taxon, taxa=TAXA)
    render_memo_feed(memos_for_feeds, taxon=taxon)
    for t in taxon.get("children", []):
        build_taxon_pages_recursive(t)


for taxon in TAXA:
    build_taxon_pages_recursive(taxon)

for memo in ALL_MEMOS:
    render(f"{memo['slug']}.html", "memo.html", title=memo["title"], memo=memo)

for error in ALL_ERRORS:
    render(f"{error['slug']}.html", "error.html", title=error["title"], page=error)

#!/usr/bin/env python3

"""build

Usage:
  build [--drafts] [--cache=<dir>] [--out=<dir>] [--root=<url>]
  build (-h | --help)

Options:
  -h --help       Show this screen.
  --drafts        Include draft memos as well.
  --cache=<dir>   Directory to cache generated HTML in [default: _cache]
  --out=<dir>     Directory to generate site in [default: _site]
  --root=<url>    Root of the website [default: https://memo.barrucadu.co.uk/]

"""

import hashlib
import jinja2
import os
import pypandoc
import subprocess
import yaml

from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from distutils import dir_util, file_util
from docopt import docopt

args = docopt(__doc__)
OUT_DIR = args["--out"]
BASE_HREF = args["--root"]
DRAFT_MODE = args["--drafts"]
CACHE_DIR = args["--cache"]

JINJA2_ENV = jinja2.Environment(
    autoescape=jinja2.select_autoescape(["html", "xml"]),
    loader=jinja2.FileSystemLoader("_templates"),
)

TAXON_DIR = "taxon"

DATE_ISO_FORMAT = "%Y-%m-%d"
DATE_PP_FORMAT = "%b %-d, %Y"


# this is a list so they can be ordered
TAXA = [
    {"name": "General", "slug": "general"},
    {"name": "Games", "slug": "general-games", "parent": "general"},
    {"name": "Weeknotes", "slug": "weeknotes"},
    {"name": "2022", "slug": "weeknotes-2022", "parent": "weeknotes"},
    {"name": "2021", "slug": "weeknotes-2021", "parent": "weeknotes"},
    {"name": "2020", "slug": "weeknotes-2020", "parent": "weeknotes"},
    {"name": "2019", "slug": "weeknotes-2019", "parent": "weeknotes"},
    {"name": "2018", "slug": "weeknotes-2018", "parent": "weeknotes"},
    {"name": "Research", "slug": "research"},
    {"name": "Deja Fu / CoCo", "slug": "research-dejafucoco", "parent": "research"},
    {"name": "Summaries", "slug": "research-summary", "parent": "research"},
    {"name": "Tech Docs", "slug": "techdocs"},
    {"name": "Practices", "slug": "techdocs-practices", "parent": "techdocs"},
    {"name": "Runbooks", "slug": "techdocs-runbooks", "parent": "techdocs"},
    {"name": "Incident Reports", "slug": "techdocs-incidents", "parent": "techdocs"},
    {"name": "Self", "slug": "self"},
    {"name": "Koans", "slug": "self-koans", "parent": "self"},
    {"name": "Possessions", "slug": "self-possessions", "parent": "self"},
    {"name": "Recipes", "slug": "self-recipes", "parent": "self"},
    {"name": "Systems", "slug": "self-systems", "parent": "self"},
]

TAXA_BY_SLUG = {taxon["slug"]: taxon for taxon in TAXA}

DEFAULT_TAXON = "general"

for taxon in TAXA:
    taxon["long_name"] = taxon["name"]
    taxon["has_children"] = False
    taxon["link"] = f"{TAXON_DIR}/{taxon['slug']}.html"
    taxon["permalink"] = f"{BASE_HREF}{taxon['link']}"
    taxon["feed_link"] = f"{TAXON_DIR}/{taxon['slug']}.xml"
    taxon["feed_permalink"] = f"{BASE_HREF}{taxon['feed_link']}"
    taxon["parent"] = taxon.get("parent", "")
    if taxon["parent"]:
        parent = TAXA_BY_SLUG[taxon["parent"]]
        parent["has_children"] = True
        taxon["long_name"] = f"{parent['long_name']} ({taxon['name']})"
        taxon["parent_name"] = parent["long_name"]
        taxon["parent_link"] = parent["link"]
        taxon["draft"] = taxon.get("draft", parent.get("draft", False))


def title_for(taxon=None):
    """Title for a memo listing or feed."""

    if taxon is not None:
        return f"barrucadu's memos - {taxon['long_name']}"
    else:
        return "barrucadu's memos"


def pandocise_memo(fname, text):
    """Render a memo's content using pandoc."""

    text_hash = hashlib.sha256()
    text_hash.update(text.encode())
    cache_file = os.path.join(CACHE_DIR, f"sha256-{text_hash.hexdigest()}.html")
    try:
        rendered = open(cache_file).read()
    except OSError:
        _, fmt = os.path.splitext(fname)
        fmt = fmt[1:]
        if fmt == "lhs":
            fmt = "markdown+literate_haskell"

        rendered = pypandoc.convert_text(
            text,
            "html",
            format=fmt,
            filters=[
                "pandoc-filter-sidenote",
                "pandoc-filter-transform-code",
            ],
            extra_args=[
                "--no-highlight",
            ],
        )
        try:
            open(cache_file, "w").write(rendered)
        except OSError as err:
            print(f"could not cache generated HTML for {fname}: {err.strerror}")

    toc = []
    for h2 in BeautifulSoup(rendered, features="html.parser").find_all("h2"):
        toc.append(
            {
                "title": h2.text,
                "anchor": h2["id"],
            }
        )

    return rendered, toc


ALL_MEMOS = []
for fname in os.listdir("memos"):
    fpath = os.path.join("memos", fname)
    if not os.path.isfile(fpath):
        continue

    with open(fpath, "r") as f:
        lines = f.readlines()
        metadata_end_idx = lines[1:].index("---\n") + 1
        text_start_idx = metadata_end_idx + 1
        memo = yaml.load("".join(lines[1:metadata_end_idx]), Loader=yaml.SafeLoader)

        # default metadata
        if "slug" not in memo:
            memo["slug"], _ = os.path.splitext(os.path.basename(fpath))
        if "published" not in memo:
            datestr = subprocess.check_output(
                [
                    "git",
                    "log",
                    "--diff-filter=A",
                    "--follow",
                    "--date=short",
                    "--format=%ad",
                    "-1",
                    "--",
                    fpath,
                ]
            )
            try:
                memo["published"] = datetime.strptime(datestr.decode("utf-8").strip(), "%Y-%m-%d")
            except Exception:
                # this will be reached if the file hasn't been committed
                memo["published"] = datetime.now()
        memo["modified"] = memo.get("modified", memo.get("date", memo["published"]))
        if not isinstance(memo["published"], datetime):
            memo["published"] = datetime(
                memo["published"].year, memo["published"].month, memo["published"].day
            )
        if not isinstance(memo["modified"], datetime):
            memo["modified"] = datetime(
                memo["modified"].year, memo["modified"].month, memo["modified"].day
            )
        if memo["published"] > memo["modified"]:
            memo["published"] = memo["modified"]
        memo["published_iso"] = memo.get(
            "published_iso", memo["published"].strftime(DATE_ISO_FORMAT)
        )
        memo["published_pp"] = memo.get("published_pp", memo["published"].strftime(DATE_PP_FORMAT))
        memo["modified_iso"] = memo.get("modified_iso", memo["modified"].strftime(DATE_ISO_FORMAT))
        memo["modified_pp"] = memo.get("modified_pp", memo["modified"].strftime(DATE_PP_FORMAT))
        memo["link"] = f"{memo['slug']}.html"
        memo["permalink"] = f"{BASE_HREF}{memo['slug']}.html"

        # get the taxon
        taxon_slug = memo.get("taxon", DEFAULT_TAXON)
        taxon = TAXA_BY_SLUG[taxon_slug]
        memo["taxon"] = taxon
        memo["taxa"] = [taxon]
        while taxon["parent"]:
            taxon = TAXA_BY_SLUG[taxon["parent"]]
            memo["taxa"].append(taxon)

        # render the body
        memo["text"] = "".join(lines[text_start_idx:])
        memo["body"], toc = pandocise_memo(fname, memo["text"])
        if toc:
            memo["toc"] = toc

    if memo.get("draft", False) and not DRAFT_MODE:
        continue
    ALL_MEMOS.append(memo)

MEMOS_BY_SLUG = {memo["slug"]: memo for memo in ALL_MEMOS}
for memo in ALL_MEMOS:
    if "superseded_by" in memo:
        memo["superseded_by"] = MEMOS_BY_SLUG[memo["superseded_by"]]

HASHED_LINKS = {}
for fname in os.listdir("hashed-static"):
    fpath = os.path.join("hashed-static", fname)
    if not os.path.isfile(fpath):
        continue

    file_hash = hashlib.sha256()
    with open(fpath, "rb") as f:
        while True:
            data = f.read(65536)
            if not data:
                break
            file_hash.update(data)
    base, ext = os.path.splitext(fname)
    HASHED_LINKS[fname] = f"{base}-sha256-{file_hash.hexdigest()}{ext}"


def render(link, template, **metadata):
    with open(os.path.join(OUT_DIR, link), "w") as f:
        rendered = JINJA2_ENV.get_template(template).render(
            base_href=BASE_HREF,
            hashed_links=HASHED_LINKS,
            site_name=title_for(),
            is_root=link == "index.html",
            is_memo=template == "memo.html",
            link=link,
            permalink=f"{BASE_HREF}{link}",
            **metadata,
        )
        print(rendered, file=f)


def render_memo_list(memos, taxon=None, taxa=[]):
    """Render a memo listing page."""

    metadata = {
        "title": title_for(taxon=taxon),
        "taxa": taxa,
    }

    link = "index.html"
    if taxon is not None:
        link = os.path.join(TAXON_DIR, taxon["slug"] + ".html")
        metadata["taxon"] = taxon
        memos = [memo for memo in memos if taxon in memo["taxa"]]

    if memos:
        metadata["memos"] = memos
    else:
        raise Exception(f"no memos (taxon={taxon})")

    render(link, "index.html" if link == "index.html" else "list.html", **metadata)


def render_memo_feed(memos, taxon=None, num=10):
    """Render a memo listing feed."""

    link = "atom.xml"
    if taxon is not None:
        link = os.path.join(TAXON_DIR, taxon["slug"] + ".xml")
        memos = [memo for memo in memos if taxon in memo["taxa"]]

    metadata = {
        "title": title_for(taxon=taxon),
        "taxon": taxon,
        "memos": memos[:num],
    }
    if memos:
        metadata["feed_date"] = memos[0]["modified_iso"]

    render(link, "atom.xml", **metadata)


memos_for_lists = sorted(
    [memo for memo in ALL_MEMOS if "superseded_by" not in memo],
    key=lambda memo: memo["modified"] + timedelta(days=(365 * 1000 if "important" in memo else 0)),
    reverse=True,
)

memos_for_feeds = sorted(
    [memo for memo in memos_for_lists], key=lambda memo: memo["modified"], reverse=True
)

dir_util.copy_tree("static", OUT_DIR)
dir_util.copy_tree("MathJax/es5", os.path.join(OUT_DIR, "mathjax"))

dir_util.mkpath(os.path.join(OUT_DIR, TAXON_DIR))

for source, target in HASHED_LINKS.items():
    file_util.copy_file(os.path.join("hashed-static", source), os.path.join(OUT_DIR, target))

render("robots.txt", "robots.txt")
render("sitemap.xml", "sitemap.xml", memos=ALL_MEMOS, taxa=TAXA)

render_memo_list(memos_for_lists, taxa=TAXA)
render_memo_feed(memos_for_feeds)


def build_taxon_pages_recursive(taxon):
    render_memo_list(memos_for_lists, taxon=taxon, taxa=TAXA)
    render_memo_feed(memos_for_feeds, taxon=taxon)
    for t in taxon.get("children", []):
        build_taxon_pages_recursive(t)


for taxon in TAXA:
    build_taxon_pages_recursive(taxon)

for memo in ALL_MEMOS:
    render(f"{memo['slug']}.html", "memo.html", title=memo["title"], memo=memo)
